{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncate SVD example\n",
    "\n",
    "Truncated Singular Value Decomposition (SVD) is a matrix factorization technique that factors a matrix M into the three matrices U, Σ, and V. This is very similar to PCA, excepting that the factorization for SVD is done on the data matrix, whereas for PCA, the factorization is done on the covariance matrix. Typically, SVD is used under the hood to find the principle components of a matrix.\n",
    "\n",
    "Like PCA, Truncate PCD is used to reduce the number of dimensions available in a matrix.\n",
    "\n",
    "A couple of good videos to watch on this topic -\n",
    "\n",
    "1. https://www.youtube.com/watch?v=P5mlg91as1c\n",
    "\n",
    "2. https://www.youtube.com/watch?v=UyAfmAZU_WI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data to run Truncate SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.target_names)\n",
    "print(np.unique(newsgroups_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "\n",
      "Seems to be, barring evidence to the contrary, that Koresh was simply\n",
      "another deranged fanatic who thought it neccessary to take a whole bunch of\n",
      "folks with him, children and all, to satisfy his delusional mania. Jim\n",
      "Jones, circa 1993.\n",
      "\n",
      "\n",
      "Nope - fruitcakes like Koresh have been demonstrating such evil corruption\n",
      "for centuries.\n",
      "\n",
      " >In article <1993Apr19.020359.26996@sq.sq.com>, msb@sq.sq.com (Mark Brader) \n",
      "\n",
      "MB>                                                             So the\n",
      "MB> 1970 figure seems unlikely to actually be anything but a perijove.\n",
      "\n",
      "JG>Sorry, _perijoves_...I'm not used to talking this language.\n",
      "\n",
      "Couldn't we just say periapsis or apoapsis?\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(newsgroups_train.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['comp.graphics', 'talk.religion.misc', 'sci.space'], dtype='<U18')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(newsgroups_train.target_names)[newsgroups_train.target[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 26576)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "x_input = vectorizer.fit_transform(newsgroups_train.data).todense()\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26576,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cosmonauts', 'cosmos', 'cosponsored', 'cost', 'costa', 'costar',\n",
       "       'costing', 'costly', 'costruction', 'costs', 'cosy', 'cote',\n",
       "       'couched', 'couldn', 'council', 'councils', 'counsel',\n",
       "       'counselees', 'counselor', 'count'], dtype='<U80')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[7000:7020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate Truncate SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate first using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 s, sys: 1.13 s, total: 43.7 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "%time U, s, Vh = linalg.svd(x_input,full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2034, 2034)\n",
      "(2034,)\n",
      "(2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "print (U.shape)\n",
    "print(s.shape)\n",
    "print(Vh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.33926985e+02 2.91510127e+02 2.40711377e+02 ... 1.86503480e-15\n",
      " 1.50688986e-15 1.35283161e-15]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>variance_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>433.93</td>\n",
       "      <td>2.262575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>291.51</td>\n",
       "      <td>1.519976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.71</td>\n",
       "      <td>1.255097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>220.00</td>\n",
       "      <td>1.147112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182.74</td>\n",
       "      <td>0.952833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>168.15</td>\n",
       "      <td>0.876759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148.16</td>\n",
       "      <td>0.772528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128.79</td>\n",
       "      <td>0.671530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>126.49</td>\n",
       "      <td>0.659538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>118.35</td>\n",
       "      <td>0.617094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>113.45</td>\n",
       "      <td>0.591545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112.66</td>\n",
       "      <td>0.587426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>104.87</td>\n",
       "      <td>0.546808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100.22</td>\n",
       "      <td>0.522562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>88.52</td>\n",
       "      <td>0.461556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>83.90</td>\n",
       "      <td>0.437467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>81.45</td>\n",
       "      <td>0.424692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>79.16</td>\n",
       "      <td>0.412752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>76.66</td>\n",
       "      <td>0.399717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69.40</td>\n",
       "      <td>0.361862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>68.19</td>\n",
       "      <td>0.355553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67.11</td>\n",
       "      <td>0.349921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66.31</td>\n",
       "      <td>0.345750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>63.11</td>\n",
       "      <td>0.329065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>62.23</td>\n",
       "      <td>0.324476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>58.71</td>\n",
       "      <td>0.306123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>58.07</td>\n",
       "      <td>0.302786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56.11</td>\n",
       "      <td>0.292566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55.86</td>\n",
       "      <td>0.291262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53.70</td>\n",
       "      <td>0.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    variance  variance_pct\n",
       "0     433.93      2.262575\n",
       "1     291.51      1.519976\n",
       "2     240.71      1.255097\n",
       "3     220.00      1.147112\n",
       "4     182.74      0.952833\n",
       "5     168.15      0.876759\n",
       "6     148.16      0.772528\n",
       "7     128.79      0.671530\n",
       "8     126.49      0.659538\n",
       "9     118.35      0.617094\n",
       "10    113.45      0.591545\n",
       "11    112.66      0.587426\n",
       "12    104.87      0.546808\n",
       "13    100.22      0.522562\n",
       "14     88.52      0.461556\n",
       "15     83.90      0.437467\n",
       "16     81.45      0.424692\n",
       "17     79.16      0.412752\n",
       "18     76.66      0.399717\n",
       "19     69.40      0.361862\n",
       "20     68.19      0.355553\n",
       "21     67.11      0.349921\n",
       "22     66.31      0.345750\n",
       "23     63.11      0.329065\n",
       "24     62.23      0.324476\n",
       "25     58.71      0.306123\n",
       "26     58.07      0.302786\n",
       "27     56.11      0.292566\n",
       "28     55.86      0.291262\n",
       "29     53.70      0.280000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_df = pd.DataFrame(s).round(2)\n",
    "s_df.rename(columns={0:\"variance\"},inplace=True)\n",
    "s_df[\"variance_pct\"] = s_df[\"variance\"]*100.0/s_df[\"variance\"].sum()\n",
    "s_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_From the value of S (Σ), it can be seen the weights are scattered and distributed across multiple words (which is understandable for such documents). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.40971949e-03 -1.14531979e-02 -2.16949925e-05 ... -5.71798766e-06\n",
      "  -1.14359753e-05 -1.09243411e-03]\n",
      " [-3.56688261e-03 -1.76916681e-02 -3.04483622e-05 ... -7.73124401e-06\n",
      "  -1.54624880e-05 -1.85490440e-03]\n",
      " [ 9.49713213e-04 -2.28284545e-02 -2.33939629e-05 ... -1.22019598e-05\n",
      "  -2.44039195e-05  1.50537828e-03]\n",
      " ...\n",
      " [-7.98329636e-03  8.54523075e-05 -6.51951431e-03 ... -2.62895556e-05\n",
      "  -1.76065710e-05  4.79428021e-07]\n",
      " [-1.63296813e-03  2.47318168e-04 -1.86095724e-04 ...  5.35465333e-06\n",
      "   1.39548625e-05 -1.42946143e-04]\n",
      " [ 4.14026862e-04 -1.29658375e-03 -4.80365443e-04 ...  1.41504622e-05\n",
      "   5.47468666e-05  5.88689486e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(Vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out top words in the top 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_words=8\n",
    "\n",
    "def show_topics(a):\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[-num_top_words-1:]]\n",
    "    topic_words = ([top_words(t) for t in a])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pub data gif images graphics file edu image jpeg',\n",
       " 'color file pub space data graphics gif edu jpeg',\n",
       " 'matthew satellite people edu graphics god launch jesus space',\n",
       " 'atheism atheists satellite people matthew launch god jesus space',\n",
       " 'edu pub analysis processing space graphics jpeg data image',\n",
       " 'religion believe prophecy religious atheism matthew atheists god jesus',\n",
       " 'probe mars market lunar satellite commercial nasa space launch',\n",
       " 'mars lunar surface probe ftp nasa available data image',\n",
       " 'premises argumentum ad true atheists example conclusion fallacy argument',\n",
       " 'mars moon surface theory data image larson probe space']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using abs as we need to pick up words that have either +ve or -ve heavy weights\n",
    "show_topics(np.abs(Vh[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate using scikit learn TruncateSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10)\n",
    "svd_transformed = svd.fit_transform(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([90.64507815, 41.57611948, 26.9144205 , 23.63770842, 16.41821839,\n",
       "       13.83983333, 10.76926986,  8.15117348,  7.86458302,  6.88208483])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21206798, 0.09726909, 0.06296742, 0.05530141, 0.03841112,\n",
       "       0.03237886, 0.02519518, 0.01906992, 0.01839947, 0.01610078])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_First 10 components explain very little variance. More components will require to be taken into account._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.40971948e-03,  1.14531979e-02,  2.16949924e-05, ...,\n",
       "         5.71798669e-06,  1.14359734e-05,  1.09243411e-03],\n",
       "       [-3.56688198e-03, -1.76916530e-02, -3.04483508e-05, ...,\n",
       "        -7.73131066e-06, -1.54626213e-05, -1.85490432e-03],\n",
       "       [-9.49720119e-04,  2.28284087e-02,  2.33938394e-05, ...,\n",
       "         1.22014265e-05,  2.44028531e-05, -1.50537818e-03],\n",
       "       ...,\n",
       "       [ 2.17172433e-03,  4.32226412e-02,  1.25511772e-04, ...,\n",
       "        -3.74205502e-05, -7.48411004e-05, -1.60929401e-03],\n",
       "       [-3.87402588e-04,  4.90966885e-03,  3.02618036e-06, ...,\n",
       "        -1.38485613e-05, -2.76971226e-05, -1.50091441e-04],\n",
       "       [-3.07858550e-03,  1.41343220e-02,  3.77826186e-06, ...,\n",
       "         3.13907212e-05,  6.27814424e-05, -5.62417736e-04]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
